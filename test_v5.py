import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import seaborn as sns
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="RFM-–∞–Ω–∞–ª–∏–∑", layout="wide")
st.title('üìä –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ —Ä–µ—Ç–µ–π–ª–∞')
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ XLSX")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª", type=["xlsx"], key="file_uploader")

# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
@st.cache_data
def load_data(file):
    return pd.read_excel(file)

if uploaded_file is not None:
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        Retail_df = load_data(uploaded_file)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        required_columns = ['CustomerID', 'TotalSpend', 'NumTransactions', 'Frequency', 'UniqueCategories']
        if not all(col in Retail_df.columns for col in required_columns):
            st.error("‚ùå –û—à–∏–±–∫–∞: –í —Ñ–∞–π–ª–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏")
            st.stop()

        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        Retail_df = Retail_df.dropna()
        if Retail_df.empty:
            st.error("‚ùå –û—à–∏–±–∫–∞: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")
            st.stop()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        numeric_cols = ['TotalSpend', 'NumTransactions', 'Frequency', 'UniqueCategories']
        for col in numeric_cols:
            Retail_df[col] = pd.to_numeric(Retail_df[col], errors='coerce')
        
        if Retail_df[numeric_cols].isnull().any().any():
            st.error("‚ùå –û—à–∏–±–∫–∞: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
            st.stop()

        # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features = numeric_cols
        X = Retail_df[features]

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # –ü–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        with st.expander("üîç –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤"):
            cluster_range = range(2, 11)
            cluster_errors = []
            silhouette_scores = []

            for num_clusters in cluster_range:
                clusters = KMeans(n_clusters=num_clusters, random_state=42)
                clusters.fit(X_scaled)
                cluster_errors.append(clusters.inertia_)
                if len(np.unique(clusters.labels_)) > 1:
                    silhouette_scores.append(silhouette_score(X_scaled, clusters.labels_))
                else:
                    silhouette_scores.append(0)

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))
            
            ax1.plot(cluster_range, cluster_errors, marker='o')
            ax1.set_title('–ú–µ—Ç–æ–¥ –ª–æ–∫—Ç—è')
            ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
            ax1.set_ylabel('Inertia')
            
            ax2.plot(cluster_range, silhouette_scores, marker='o')
            ax2.set_title('Silhouette Score')
            ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤')
            ax2.set_ylabel('Score')
            
            st.pyplot(fig)
            plt.close(fig)

        # –í—ã–±–æ—Ä —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        n_clusters = st.slider("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", 2, 10, 3, key='n_clusters')

        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        Retail_df['cluster_label'] = kmeans.fit_predict(X_scaled)

        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        st.header("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        
        with st.container():
            col1, col2 = st.columns(2)
            
            with col1:
                # TotalSpend vs Frequency
                fig1, ax = plt.subplots(figsize=(10, 6))
                scatter = ax.scatter(
                    Retail_df['TotalSpend'], 
                    Retail_df['Frequency'], 
                    c=Retail_df['cluster_label'], 
                    cmap='viridis'
                )
                ax.set_title('Total Spend vs Frequency')
                ax.set_xlabel('–û–±—â–∞—è —Å—É–º–º–∞ –ø–æ–∫—É–ø–æ–∫')
                ax.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ–∫—É–ø–æ–∫')
                plt.colorbar(scatter, ax=ax)
                st.pyplot(fig1)
                plt.close(fig1)

            with col2:
                # PCA –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                pca = PCA(n_components=2)
                X_pca = pca.fit_transform(X_scaled)
                
                fig2, ax = plt.subplots(figsize=(10, 6))
                scatter = ax.scatter(
                    X_pca[:, 0], 
                    X_pca[:, 1], 
                    c=Retail_df['cluster_label'], 
                    cmap='viridis'
                )
                ax.set_title('PCA –ø—Ä–æ–µ–∫—Ü–∏—è')
                ax.set_xlabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')
                ax.set_ylabel('–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')
                plt.colorbar(scatter, ax=ax)
                st.pyplot(fig2)
                plt.close(fig2)

        # –ê–Ω–∞–ª–∏–∑ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        st.header("üìå –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        
        # –û–ø–∏—Å–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_descriptions = {
            'TotalSpend': '–û–±—â–∞—è —Å—É–º–º–∞ –ø–æ–∫—É–ø–æ–∫',
            'NumTransactions': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π',
            'Frequency': '–ß–∞—Å—Ç–æ—Ç–∞ –ø–æ–∫—É–ø–æ–∫',
            'UniqueCategories': '–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π'
        }

        # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –º–µ–¥–∏–∞–Ω—ã
        global_medians = Retail_df[features].median(numeric_only=True)

        # –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è
        def generate_cluster_description(cluster_data):
            description = []
            for feature in features:
                cluster_median = cluster_data[feature].median()
                global_median = global_medians[feature]
                
                diff = cluster_median - global_median
                diff_percent = abs(diff) / global_median * 100
                
                if diff > 0:
                    trend = "‚ñ≤ –í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ"
                    emoji = "üî∫"
                else:
                    trend = "‚ñº –ù–∏–∂–µ —Å—Ä–µ–¥–Ω–µ–≥–æ" 
                    emoji = "üîª"
                
                if abs(diff_percent) > 20:
                    intensity = "–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ"
                    emoji = "‚ùó" + emoji
                elif abs(diff_percent) > 10:
                    intensity = "—É–º–µ—Ä–µ–Ω–Ω–æ"
                else:
                    intensity = "–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ"
                    emoji = "‚ûñ"
                
                description.append(
                    f"{emoji} **{feature_descriptions[feature]}**: "
                    f"{trend} ({intensity}, {diff_percent:.1f}%)"
                )
            return "\n\n".join(description)

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        for cluster_id in sorted(Retail_df['cluster_label'].unique()):
            cluster_data = Retail_df[Retail_df['cluster_label'] == cluster_id]
            
            with st.expander(f"## –ö–ª–∞—Å—Ç–µ—Ä {cluster_id} ({len(cluster_data)} –∫–ª–∏–µ–Ω—Ç–æ–≤)", expanded=True):
                col1, col2 = st.columns([1, 3])
                
                with col1:
                    st.metric(
                        label="–î–æ–ª—è –æ—Ç –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤",
                        value=f"{len(cluster_data)/len(Retail_df):.1%}"
                    )
                    st.write("**–ú–µ–¥–∏–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:**")
                    st.dataframe(
                        cluster_data[features].median().to_frame().T.style.format("{:.1f}"),
                        hide_index=True
                    )
                
                with col2:
                    st.write("**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**")
                    st.markdown(generate_cluster_description(cluster_data))
                
                st.markdown("---")

        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.header("üì• –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            Retail_df.to_excel(writer, index=False)
        output.seek(0)
        
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏",
            data=output,
            file_name='clustered_customers.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except Exception as e:
        st.error(f"‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        st.stop()
else:
    st.info("‚ÑπÔ∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞")