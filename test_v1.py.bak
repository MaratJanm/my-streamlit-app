import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import io

# Заголовок приложения
st.title('Кластеризация клиентов ретейла')
st.write('Пожалуйста, загрузите файл в формате .xlsx для анализа клиентов.')
st.write('Используйте заголовки: CustomerID, PurchaseDate, TotalSpend, NumTransactions, Frequency, UniqueCategories, LoyaltyProgram.')

# Загрузка файла
uploaded_file = st.file_uploader("Выберите файл", type=["xlsx"])

# Кэширование данных
@st.cache_data
def load_data(file):
    return pd.read_excel(file)

if uploaded_file is not None:
    # Чтение данных
    Retail_df = load_data(uploaded_file)

    # Проверка наличия необходимых столбцов
    required_columns = ['CustomerID', 'PurchaseDate', 'TotalSpend', 'NumTransactions', 'Frequency', 'UniqueCategories', 'LoyaltyProgram']
    if not all(col in Retail_df.columns for col in required_columns):
        st.error("Ошибка: Недостаточно заголовков в загруженном файле. Пожалуйста, убедитесь, что файл содержит все необходимые заголовки.")
    else:
        # Преобразование даты
        Retail_df['PurchaseDate'] = pd.to_datetime(Retail_df['PurchaseDate'], format='%Y-%m-%d %H:%M:%S')

        # Удаление строк с пропущенными значениями
        Retail_df = Retail_df.dropna()

        # Вывод первых строк данных
        st.write("Первые 10 строк данных:")
        st.write(Retail_df.head(10))

        # Выбор признаков для кластеризации
        features = ['TotalSpend', 'NumTransactions', 'Frequency', 'UniqueCategories']
        X = Retail_df[features]

        # Масштабирование данных
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Метод локтя для определения оптимального числа кластеров
        cluster_range = range(1, 10)
        cluster_errors = []

        for num_clusters in cluster_range:
            clusters = KMeans(n_clusters=num_clusters, random_state=42)
            clusters.fit(X_scaled)
            cluster_errors.append(clusters.inertia_)

        clusters_df = pd.DataFrame({"num_clusters": cluster_range, "cluster_errors": cluster_errors})

        # Визуализация метода локтя
        st.write("Метод локтя для определения числа кластеров:")
        plt.figure(figsize=(12, 6))
        plt.plot(clusters_df.num_clusters, clusters_df.cluster_errors, marker="o")
        plt.title('Метод локтя')
        plt.xlabel('Количество кластеров')
        plt.ylabel('Ошибка кластера (inertia)')
        plt.grid(True)
        st.pyplot(plt)

        # Кластеризация KMeans
        n_clusters = st.slider("Выберите количество кластеров", min_value=2, max_value=10, value=3)
        clusters = KMeans(n_clusters=n_clusters, random_state=42)
        Retail_df["cluster_label"] = clusters.fit_predict(X_scaled)

        # Визуализация кластеров
        st.write("График кластеризации клиентов по KMeans:")
        plt.figure(figsize=(10, 6))
        plt.scatter(Retail_df['TotalSpend'], Retail_df['Frequency'],
                    c=Retail_df['cluster_label'], cmap='viridis', marker='o')
        plt.title('Кластеры клиентов по KMeans')
        plt.xlabel('Total Spend (общая сумма покупок)')
        plt.ylabel('Frequency (частота покупок)')
        plt.colorbar(label='Cluster Label')
        plt.grid(True)
        st.pyplot(plt)

        # Описание кластеров
        st.write("Средние значения по кластерам:")
        cluster_means = Retail_df.groupby('cluster_label').mean()
        st.write(cluster_means)

        # Интерпретация кластеров
        for i in range(n_clusters):
            cluster_data = Retail_df[Retail_df['cluster_label'] == i]
            st.write(f"\n#### Кластер {i}:")
            if i == 0:
                st.write("Клиенты с низкими затратами и низкой частотой покупок.")
            elif i == 1:
                st.write("Клиенты со средними затратами и средней частотой покупок.")
            elif i == 2:
                st.write("Клиенты с высокими затратами и высокой частотой покупок.")
            st.write(cluster_data.head(5))

        # Скачивание результатов
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            Retail_df.to_excel(writer, sheet_name='Кластеризация', index=False)
        output.seek(0)

        st.success("Кластеризация завершена успешно!")

        st.download_button(
            label="Скачать файл",
            data=output,
            file_name='clients_clusters.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )