import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
import seaborn as sns
import io

# Минималистичный заголовок
st.title('Кластеризация клиентов ретейла')
st.write('Пожалуйста, загрузите файл в формате .xlsx для анализа клиентов.')
st.write('Используйте заголовки: CustomerID, TotalSpend, NumTransactions, Frequency, UniqueCategories.')

# Загрузка файла
uploaded_file = st.file_uploader("Выберите файл", type=["xlsx"])

@st.cache_data
def load_data(file):
    return pd.read_excel(file)

if uploaded_file is not None:
    try:
        # Загрузка и проверка данных
        Retail_df = load_data(uploaded_file)
        
        required_columns = ['CustomerID', 'TotalSpend', 'NumTransactions', 'Frequency', 'UniqueCategories']
        if not all(col in Retail_df.columns for col in required_columns):
            st.error("Ошибка: Недостаточно необходимых колонок в файле")
            st.stop()

        Retail_df = Retail_df.dropna()
        if Retail_df.empty:
            st.error("Ошибка: Нет данных после очистки")
            st.stop()

        # Проверка числовых значений
        numeric_cols = required_columns[1:]
        for col in numeric_cols:
            Retail_df[col] = pd.to_numeric(Retail_df[col], errors='coerce')
        
        if Retail_df[numeric_cols].isnull().any().any():
            st.error("Ошибка: Некорректные значения в данных")
            st.stop()

        # Масштабирование данных
        X = Retail_df[numeric_cols]
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Настройки кластеризации
        st.sidebar.header("Параметры анализа")
        method = st.sidebar.selectbox(
            "Метод кластеризации",
            ["K-Means", "DBSCAN", "Иерархическая", "GMM"],
            index=0
        )

        # Параметры методов
        if method == "K-Means":
            n_clusters = st.sidebar.slider("Количество кластеров", 2, 10, 3)
            
            # Метод локтя и силуэт
            st.subheader("Оптимизация числа кластеров")
            
            cluster_range = range(2, 11)
            inertias = []
            silhouettes = []
            
            for k in cluster_range:
                kmeans = KMeans(n_clusters=k, random_state=42)
                labels = kmeans.fit_predict(X_scaled)
                inertias.append(kmeans.inertia_)
                if len(set(labels)) > 1:
                    silhouettes.append(silhouette_score(X_scaled, labels))
                else:
                    silhouettes.append(0)
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
            ax1.plot(cluster_range, inertias, marker='o')
            ax1.set_title('Метод локтя')
            ax1.set_xlabel('Количество кластеров')
            
            ax2.plot(cluster_range, silhouettes, marker='o')
            ax2.set_title('Silhouette Score')
            ax2.set_xlabel('Количество кластеров')
            
            st.pyplot(fig)
            plt.close(fig)

        elif method == "DBSCAN":
            eps = st.sidebar.slider("Радиус (eps)", 0.1, 1.0, 0.5, 0.05)
            min_samples = st.sidebar.slider("Минимальное количество", 1, 10, 5)

        elif method == "Иерархическая":
            n_clusters = st.sidebar.slider("Количество кластеров", 2, 10, 3)
            linkage = st.sidebar.selectbox("Тип связи", ["ward", "complete", "average", "single"])

        elif method == "GMM":
            n_clusters = st.sidebar.slider("Количество кластеров", 2, 10, 3)

        # Применение модели
        if method == "K-Means":
            model = KMeans(n_clusters=n_clusters, random_state=42)
        elif method == "DBSCAN":
            model = DBSCAN(eps=eps, min_samples=min_samples)
        elif method == "Иерархическая":
            model = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)
        elif method == "GMM":
            model = GaussianMixture(n_components=n_clusters, random_state=42)
        
        labels = model.fit_predict(X_scaled) if method != "GMM" else model.fit(X_scaled).predict(X_scaled)
        Retail_df['Cluster'] = labels

        # Визуализация
        st.subheader("Результаты кластеризации")
        
        col1, col2 = st.columns(2)
        with col1:
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.scatter(
                Retail_df['TotalSpend'], 
                Retail_df['Frequency'], 
                c=Retail_df['Cluster'], 
                cmap='tab10',
                alpha=0.7
            )
            ax.set_title('Сумма покупок vs Частота')
            ax.set_xlabel('TotalSpend')
            ax.set_ylabel('Frequency')
            st.pyplot(fig)
            plt.close(fig)

        with col2:
            pca = PCA(n_components=2)
            X_pca = pca.fit_transform(X_scaled)
            
            fig, ax = plt.subplots(figsize=(8, 5))
            ax.scatter(
                X_pca[:, 0], 
                X_pca[:, 1], 
                c=Retail_df['Cluster'], 
                cmap='tab10',
                alpha=0.7
            )
            ax.set_title('PCA проекция')
            ax.set_xlabel('Компонент 1')
            ax.set_ylabel('Компонент 2')
            st.pyplot(fig)
            plt.close(fig)

        # Анализ кластеров
        st.subheader("Характеристики кластеров")
        
        cluster_stats = Retail_df.groupby('Cluster')[numeric_cols].median()
        global_median = Retail_df[numeric_cols].median()
        
        # Рассчитываем общее количество клиентов
        total_clients = len(Retail_df)
        
        for cluster in sorted(cluster_stats.index):
            # Получаем количество клиентов в кластере
            cluster_size = len(Retail_df[Retail_df['Cluster'] == cluster])
            # Рассчитываем процент
            cluster_percent = (cluster_size / total_clients) * 100
            
            st.write(f"### Кластер {cluster} ({cluster_percent:.1f}%)")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Медианные значения:**")
                st.dataframe(cluster_stats.loc[cluster].to_frame().T)
                
            with col2:
                st.write("**Отклонение от общего среднего:**")
                deviations = (cluster_stats.loc[cluster] - global_median) / global_median * 100
                for feature, value in deviations.items():
                    st.write(f"- {feature}: {value:.1f}%")
            
            st.markdown("---")

        # Экспорт результатов
        st.subheader("Экспорт данных")
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            Retail_df.to_excel(writer, index=False)
        output.seek(0)
        
        st.download_button(
            label="Скачать результаты",
            data=output,
            file_name='clusters.xlsx',
            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

    except Exception as e:
        st.error(f"Ошибка выполнения: {str(e)}")
else:
    st.info("Загрузите файл для начала анализа")